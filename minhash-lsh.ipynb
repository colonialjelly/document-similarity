{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lsh import MinHashLSH\n",
    "from minhash import MinHash\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 # shingle size\n",
    "k = 100 # number of permutations\n",
    "b = 25 # number of bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and drop empty\n",
    "df = pd.read_csv('dataset/datascience-stackoverflow-questions.csv')\n",
    "df['title'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['title'], inplace=True)\n",
    "\n",
    "# Convert to lowercase\n",
    "df['text'] = df['title'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24363/24363 [00:00<00:00, 163856.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# Break up text into shingles\n",
    "df['shingles'] = df['text'].progress_map(lambda x: utils.generate_ngrams(x.split(), n))\n",
    "\n",
    "# Drop texts that were too short for the provided shingle size\n",
    "df = df[df['shingles'].str.len() != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the minhash signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24359/24359 [00:23<00:00, 1043.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize minhash object\n",
    "minhash = MinHash(num_hashes=K)\n",
    "\n",
    "# Compute the signatures on all examples\n",
    "df['signature'] = df['shingles'].progress_map(minhash.signature)\n",
    "\n",
    "# Put all signatures into a matrix\n",
    "sig_matrix = np.array(df['signature'].tolist()).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the minashLSH object\n",
    "minhash_lsh = MinHashLSH(documents=df['shingles'].tolist(), signatures=sig_matrix, num_bands=b)\n",
    "\n",
    "# Build the LSH index\n",
    "minhash_lsh.build()\n",
    "\n",
    "# Get all candidates for all documents\n",
    "doc_candidates = minhash_lsh.doc_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all documents that have similar documents\n",
    "has_similars = list(filter(lambda x: len(doc_candidates[x]) > 1, doc_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random document\n",
    "rndm_doc_idx = np.random.choice(has_similars, 1)[0]\n",
    "rndm_doc_similars = list(doc_candidates[rndm_doc_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndm_doc = df['title'].iloc[rndm_doc_idx]\n",
    "sim_docs = df.iloc[rndm_doc_similars]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Document: \n",
      " Time series modelling\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Document: \\n\", rndm_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Documents: \n",
      "\n",
      "['Irregular time series classification',\n",
      " 'Time series prediction',\n",
      " 'Time series classification',\n",
      " 'Methods for analyzing multiple time series',\n",
      " 'Time Series segmentation',\n",
      " 'Time Series Forecasting',\n",
      " 'Categorical Multivariate Time Series',\n",
      " 'Classifying time series data that overlap',\n",
      " 'Alignment of time series',\n",
      " 'time series plot',\n",
      " 'Classification of a time series data',\n",
      " 'Time series regression',\n",
      " 'Visualizing Time Series Data',\n",
      " 'Time series decomposition',\n",
      " 'Multivariate time series classification',\n",
      " 'Multivariate Time Series Binary Classification']\n"
     ]
    }
   ],
   "source": [
    "print(\"Similar Documents: \\n\")\n",
    "pprint(sim_docs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:document-similarity] *",
   "language": "python",
   "name": "conda-env-document-similarity-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
